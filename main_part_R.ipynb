{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import lightning\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryAUROC\n",
    "\n",
    "from source.preprocessing import hdf5_to_seq, hdf5_jet_flavor\n",
    "from source.part import ParticleTransformer\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "rnd_seed = 42\n",
    "lightning.seed_everything(rnd_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchDataset(Dataset):\n",
    "    def __init__(self, sig: torch.Tensor, bkg: torch.Tensor):\n",
    "        self.x = torch.cat([sig, bkg], dim=0)\n",
    "        self.y = torch.cat([torch.ones(len(sig)), torch.zeros(len(bkg))], dim=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "\n",
    "class LitDataModule(lightning.LightningDataModule):\n",
    "    def __init__(self, batch_size=64, L=3000, num_test=10000):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        print(f\"{'='* 20} Data Size Information {'='* 20}\")\n",
    "        \n",
    "        # Sequence data\n",
    "        GGF = hdf5_to_seq('GGF.h5')\n",
    "        VBF = hdf5_to_seq('VBF.h5')\n",
    "        print(f'GGF.h5 shape: {GGF.shape}, VBF.h5 shape: {VBF.shape}')\n",
    "\n",
    "        # Jet flavor\n",
    "        GGF_info = hdf5_jet_flavor('GGF.h5')\n",
    "        VBF_info = hdf5_jet_flavor('VBF.h5')\n",
    "\n",
    "        # Number of data from real luminosity\n",
    "        BR_Haa = 0.00227\n",
    "        cross_section_GGF = 54.67 * 1000\n",
    "        cross_section_VBF = 4.278 * 1000\n",
    "\n",
    "        # Selection rate 0.9 & 0.41 from 謝豐仰\n",
    "        GGF_after_selection = cross_section_GGF * BR_Haa * L * 0.09\n",
    "        VBF_after_selection = cross_section_VBF * BR_Haa * L * 0.41\n",
    "\n",
    "        # CWoLa: (2q0g) v.s. (1q1g + 0q2g)\n",
    "        num_GGF_real = int((sum(GGF_info['2q0g']) + sum(GGF_info['1q1g']) + sum(GGF_info['0q2g'])) / GGF_info['total'] * GGF_after_selection)\n",
    "        num_VBF_real = int((sum(VBF_info['2q0g']) + sum(VBF_info['1q1g']) + sum(VBF_info['0q2g'])) / VBF_info['total'] * VBF_after_selection)\n",
    "        print(f'GGF after selection: {num_GGF_real}, VBF after selection: {num_VBF_real}')\n",
    "\n",
    "        # Randomly sampling and artificially set num_test for GGF and VBF\n",
    "        GGF_index = torch.nonzero((GGF_info['2q0g'] | GGF_info['1q1g'] | GGF_info['0q2g'])).squeeze()\n",
    "        VBF_index = torch.nonzero((VBF_info['2q0g'] | VBF_info['1q1g'] | VBF_info['0q2g'])).squeeze()\n",
    "\n",
    "        GGF_index = GGF_index[torch.randperm(len(GGF_index))]\n",
    "        VBF_index = VBF_index[torch.randperm(len(VBF_index))]\n",
    "\n",
    "        GGF_train_index = GGF_index[:int(num_GGF_real * 0.8)]\n",
    "        VBF_train_index = VBF_index[:int(num_VBF_real * 0.8)]\n",
    "\n",
    "        GGF_valid_index = GGF_index[int(num_GGF_real * 0.8):int(num_GGF_real)]\n",
    "        VBF_valid_index = VBF_index[int(num_VBF_real * 0.8):int(num_VBF_real)]\n",
    "\n",
    "        GGF_test_index  = GGF_index[int(num_GGF_real):int(num_GGF_real) + num_test]\n",
    "        VBF_test_index  = VBF_index[int(num_VBF_real):int(num_VBF_real) + num_test]\n",
    "\n",
    "        train_sig = torch.cat((\n",
    "            GGF[GGF_train_index][GGF_info['2q0g'][GGF_train_index]],\n",
    "            VBF[VBF_train_index][VBF_info['2q0g'][VBF_train_index]]\n",
    "            ), dim=0)\n",
    "        \n",
    "        train_bkg = torch.cat((\n",
    "            GGF[GGF_train_index][GGF_info['1q1g'][GGF_train_index] | GGF_info['0q2g'][GGF_train_index]],\n",
    "            VBF[VBF_train_index][VBF_info['1q1g'][VBF_train_index] | VBF_info['0q2g'][VBF_train_index]]\n",
    "            ), dim=0)\n",
    "        \n",
    "        valid_sig = torch.cat((\n",
    "            GGF[GGF_valid_index][GGF_info['2q0g'][GGF_valid_index]],\n",
    "            VBF[VBF_valid_index][VBF_info['2q0g'][VBF_valid_index]]\n",
    "            ), dim=0)\n",
    "        \n",
    "        valid_bkg = torch.cat((\n",
    "            GGF[GGF_valid_index][GGF_info['1q1g'][GGF_valid_index] | GGF_info['0q2g'][GGF_valid_index]],\n",
    "            VBF[VBF_valid_index][VBF_info['1q1g'][VBF_valid_index] | VBF_info['0q2g'][VBF_valid_index]]\n",
    "            ), dim=0)\n",
    "        \n",
    "        test_sig = VBF[VBF_test_index]\n",
    "        test_bkg = GGF[GGF_test_index]\n",
    "\n",
    "        print(f'Train signal shape: {train_sig.shape}, Train background shape: {train_bkg.shape}')\n",
    "        print(f'Valid signal shape: {valid_sig.shape}, Valid background shape: {valid_bkg.shape}')\n",
    "        print(f'Test signal shape: {test_sig.shape}, Test background shape: {test_bkg.shape}')\n",
    "        print(f\"{'='* 50}\")\n",
    "\n",
    "        # Create datasets\n",
    "        self.train_dataset = TorchDataset(train_sig, train_bkg)\n",
    "        self.valid_dataset = TorchDataset(valid_sig, valid_bkg)\n",
    "        self.test_dataset  = TorchDataset(test_sig, test_bkg)\n",
    "\n",
    "        # Calculate positive weight for loss function\n",
    "        num_pos = torch.sum(self.train_dataset.y == 1)\n",
    "        num_neg = torch.sum(self.train_dataset.y == 0)\n",
    "        self.pos_weight = torch.tensor([num_neg / num_pos], dtype=torch.float32)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.valid_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLitModel(lightning.LightningModule):\n",
    "    def __init__(self, model: nn.Module, pos_weight: torch.Tensor):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = model\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "        self.train_accuracy = BinaryAccuracy()\n",
    "        self.valid_accuracy = BinaryAccuracy()\n",
    "        self.test_accuracy = BinaryAccuracy()\n",
    "\n",
    "        self.train_auc = BinaryAUROC()\n",
    "        self.valid_auc = BinaryAUROC()\n",
    "        self.test_auc = BinaryAUROC()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:        \n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.RAdam(self.parameters(), lr=3e-4)\n",
    "\n",
    "    def _shared_step(self, batch: tuple[torch.Tensor, torch.Tensor], mode: str):\n",
    "        x, y_true = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits.view(-1), y_true.float())\n",
    "        y_pred = torch.sigmoid(logits.view(-1))\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.train_auc.update(y_pred, y_true)\n",
    "            self.train_accuracy.update(y_pred, y_true)\n",
    "        elif mode == 'valid':\n",
    "            self.valid_auc.update(y_pred, y_true)\n",
    "            self.valid_accuracy.update(y_pred, y_true)\n",
    "        elif mode == 'test':\n",
    "            self.test_auc.update(y_pred, y_true)\n",
    "            self.test_accuracy.update(y_pred, y_true)\n",
    "\n",
    "        self.log(f\"{mode}_loss\", loss, on_epoch=True, prog_bar=(mode == 'train'))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._shared_step(batch, mode='train')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._shared_step(batch, mode='valid')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._shared_step(batch, mode='test')\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.log('train_auc', self.train_auc.compute(), prog_bar=True)\n",
    "        self.log('train_accuracy', self.train_accuracy.compute(), prog_bar=True)\n",
    "        self.train_auc.reset()\n",
    "        self.train_accuracy.reset()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log('valid_auc', self.valid_auc.compute(), prog_bar=True)\n",
    "        self.log('valid_accuracy', self.valid_accuracy.compute(), prog_bar=True)\n",
    "        self.valid_auc.reset()\n",
    "        self.valid_accuracy.reset()\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        self.log('test_auc', self.test_auc.compute(), prog_bar=True)\n",
    "        self.log('test_accuracy', self.test_accuracy.compute(), prog_bar=True)\n",
    "        self.test_auc.reset()\n",
    "        self.test_accuracy.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParT_Baseline(ParticleTransformer):\n",
    "    def __init__(self):\n",
    "\n",
    "        hyperparameters = {\n",
    "            \"ParEmbed\": {\n",
    "                \"input_dim\": 3 + 3,  # (pt, eta, phi) + one-hot_encoding\n",
    "                \"embed_dim\": [128, 512, 128]\n",
    "            },\n",
    "            \"ParAtteBlock\": {\n",
    "                \"num_heads\": 8,\n",
    "                \"fc_dim\": 512,\n",
    "                \"dropout\": 0.1\n",
    "            },\n",
    "            \"ClassAtteBlock\": {\n",
    "                \"num_heads\": 8,\n",
    "                \"fc_dim\": 512,\n",
    "                \"dropout\": 0.0\n",
    "            },\n",
    "            \"num_ParAtteBlock\": 8,\n",
    "            \"num_ClassAtteBlock\": 2\n",
    "        }\n",
    "\n",
    "        super().__init__(score_dim=1, parameters=hyperparameters)\n",
    "\n",
    "class ParT_Light(ParticleTransformer):\n",
    "    def __init__(self):\n",
    "\n",
    "        hyperparameters = {\n",
    "            \"ParEmbed\": {\n",
    "                \"input_dim\": 3 + 3,  # (pt, eta, phi) + one-hot_encoding\n",
    "                \"embed_dim\": [64, 64, 64]\n",
    "            },\n",
    "            \"ParAtteBlock\": {\n",
    "                \"num_heads\": 4,\n",
    "                \"fc_dim\": 64,\n",
    "                \"dropout\": 0.1\n",
    "            },\n",
    "            \"ClassAtteBlock\": {\n",
    "                \"num_heads\": 4,\n",
    "                \"fc_dim\": 64,\n",
    "                \"dropout\": 0.0\n",
    "            },\n",
    "            \"num_ParAtteBlock\": 4,\n",
    "            \"num_ClassAtteBlock\": 1\n",
    "        }\n",
    "\n",
    "        super().__init__(score_dim=1, parameters=hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup.\n",
    "model = ParT_Light()\n",
    "batch_size = 256  # Batch size for training and validation\n",
    "L = 3000  # Luminosity in fb^-1\n",
    "num_test = 10000  # Number of testing samples\n",
    "\n",
    "# Save directory and name.\n",
    "save_dir = os.path.join('training_logs')\n",
    "preprocessing_mode = \"R\"\n",
    "name = f\"ParT_{preprocessing_mode}_{rnd_seed}\"\n",
    "version = f\"{model.__class__.__name__}_B{batch_size}\"\n",
    "\n",
    "\"\"\"Training\"\"\"\n",
    "# Lightning DataModule & Model.\n",
    "lit_data_module = LitDataModule(batch_size=batch_size, L=L, num_test=num_test)\n",
    "lit_model = BinaryLitModel(model=model, pos_weight=lit_data_module.pos_weight)\n",
    "\n",
    "# Lightning Logger & Trainer.\n",
    "logger = CSVLogger(save_dir=save_dir, name=name, version=version)\n",
    "trainer = lightning.Trainer(\n",
    "    accelerator='gpu',\n",
    "    max_epochs=100,\n",
    "    logger=logger,\n",
    "    callbacks=[ModelCheckpoint(\n",
    "            monitor='valid_auc',\n",
    "            mode='max',\n",
    "            save_top_k=5,\n",
    "            save_last=True,\n",
    "            filename='{epoch}-{valid_auc:.3f}-{valid_accuracy:.3f}',\n",
    "        )],\n",
    ")\n",
    "\n",
    "# Train and test the model.\n",
    "trainer.fit(lit_model, lit_data_module)\n",
    "trainer.test(lit_model, datamodule=lit_data_module, ckpt_path='best')\n",
    "\n",
    "# Summay of the number of parameters.\n",
    "with open(os.path.join(save_dir, name, version, 'num_params.txt'), 'w') as file_num_params:\n",
    "    for depth in range(1, 4):\n",
    "        print(f\"Model Summary (max_depth={depth}):\", file=file_num_params)\n",
    "        print(ModelSummary(lit_model, max_depth=depth), file=file_num_params)\n",
    "        print(f\"\\n{'='*100}\\n\", file=file_num_params)\n",
    "\n",
    "\"\"\"Plot Metrics\"\"\"\n",
    "metrics_csv = os.path.join(save_dir, name, version, 'metrics.csv')\n",
    "df = pd.read_csv(metrics_csv)\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(10, 6))\n",
    "metrics = ['train_loss_epoch', 'train_accuracy', 'train_auc', 'valid_loss', 'valid_accuracy', 'valid_auc']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    data = df[df[metric].notna()]\n",
    "    plot = sns.lineplot(data=data, x='epoch', y=metric, ax=ax.flat[i])\n",
    "    plot.set_title(metric)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, name, version, 'metrics.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
