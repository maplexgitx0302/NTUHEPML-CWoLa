{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "import lightning\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryAUROC\n",
    "\n",
    "try:\n",
    "    project_root = Path(__file__).parent.parent\n",
    "except NameError:\n",
    "    '''Jupyter notebook environment has no __file__ attribute.'''\n",
    "    project_root = Path.cwd().parent\n",
    "sys.path.append(project_root.as_posix())\n",
    "\n",
    "from src.data_preprocess import MCSimData\n",
    "from src.data_cwola import split_by_sv\n",
    "from src.model_cnn import CNN_Baseline, CNN_EventCNN\n",
    "from src.model_part import ParT_Baseline, ParT_Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fd24eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitDataModule(lightning.LightningDataModule):\n",
    "    def __init__(self, data_format: str, data_info: dict, include_decay: bool, num_test: int = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data_format = data_format\n",
    "        self.data_info = data_info\n",
    "        self.include_decay = include_decay\n",
    "        self.num_test = num_test\n",
    "\n",
    "        # Information of signal and background datasets\n",
    "        sig_info = data_info['signal']\n",
    "        bkg_info = data_info['background']\n",
    "\n",
    "        # Monte Carlo simulation data\n",
    "        SIG = MCSimData(sig_info['path'], include_decay=include_decay)\n",
    "        BKG = MCSimData(bkg_info['path'], include_decay=include_decay)\n",
    "\n",
    "        # Choose the representation of the dataset\n",
    "        if data_format == 'image':\n",
    "            sig_tensor = SIG.to_image()\n",
    "            bkg_tensor = BKG.to_image()\n",
    "        elif data_format == 'sequence':\n",
    "            sig_tensor = SIG.to_sequence()\n",
    "            bkg_tensor = BKG.to_sequence()\n",
    "\n",
    "        # Only keep testing data\n",
    "        _, _, _, _, test_sig, test_bkg = split_by_sv(\n",
    "            sig_tensor=sig_tensor, bkg_tensor=bkg_tensor,\n",
    "            num_train=0, num_valid=0, num_test=num_test,\n",
    "        )\n",
    "\n",
    "        # Create torch datasets\n",
    "        self.test_dataset = TensorDataset(\n",
    "            torch.cat([test_sig, test_bkg], dim=0),\n",
    "            torch.cat([torch.ones(len(test_sig)), torch.zeros(len(test_bkg))], dim=0)\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4279e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLitModel(lightning.LightningModule):\n",
    "    def __init__(self, model: nn.Module):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        self.train_accuracy = BinaryAccuracy()\n",
    "        self.valid_accuracy = BinaryAccuracy()\n",
    "        self.test_accuracy = BinaryAccuracy()\n",
    "\n",
    "        self.train_auc = BinaryAUROC()\n",
    "        self.valid_auc = BinaryAUROC()\n",
    "        self.test_auc = BinaryAUROC()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:        \n",
    "        return self.model(x)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y_true = batch\n",
    "        logits: torch.Tensor = self(x)\n",
    "        y_pred = torch.sigmoid(logits.view(-1))\n",
    "\n",
    "        self.test_auc.update(y_pred, y_true)\n",
    "        self.test_accuracy.update(y_pred, y_true)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        self.log('test_auc', self.test_auc.compute(), prog_bar=True, on_epoch=True, on_step=False)\n",
    "        self.log('test_accuracy', self.test_accuracy.compute(), prog_bar=True, on_epoch=True, on_step=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd590597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_ckpt(ckpt_dir: str, metric: str = 'valid_auc') -> str:\n",
    "    \"\"\"Find the best checkpoint file based on the specified metric.\"\"\"\n",
    "\n",
    "    # Initialize variables to store the best checkpoint\n",
    "    best_ckpt = None\n",
    "    best_value = -float('inf')\n",
    "\n",
    "    # Find the best checkpoint file\n",
    "    for ckpt_file in os.listdir(ckpt_dir):\n",
    "        if ckpt_file.startswith('epoch=') and ckpt_file.endswith('.ckpt'):\n",
    "            metrics = ckpt_file.split('-')\n",
    "            metrics = [m for m in metrics if m.startswith(metric)]\n",
    "            metric_value = eval(metrics[0].split('=')[1])\n",
    "            if metric_value > best_value:\n",
    "                best_value = metric_value\n",
    "                best_ckpt = ckpt_file\n",
    "\n",
    "    print(f\"The best checkpoint is: {best_ckpt} with {metric} = {best_value}\")\n",
    "\n",
    "    return best_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a05303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(training_channel, training_mode, training_date, inference_channel, include_decay, information=None):\n",
    "    \"\"\"Run inference on the specified model and dataset.\"\"\"\n",
    "    \n",
    "    num_channels = 2 + include_decay\n",
    "\n",
    "    with open(project_root / Path(f\"config/data_{inference_channel}.yml\"), 'r') as f:\n",
    "        data_info = yaml.safe_load(f)\n",
    "\n",
    "    df = pd.DataFrame(columns=['model', 'rnd_seed', 'test_auc', 'test_accuracy'])\n",
    "\n",
    "    for data_format, model in [\n",
    "        ('image', CNN_Baseline(num_channels=num_channels)),\n",
    "        ('image', CNN_EventCNN(num_channels=num_channels)),\n",
    "        ('sequence', ParT_Baseline(num_channels=num_channels)),\n",
    "        ('sequence', ParT_Light(num_channels=num_channels)),\n",
    "    ]:\n",
    "        lit_data_module = LitDataModule(\n",
    "            data_format=data_format,\n",
    "            data_info=data_info,\n",
    "            include_decay=include_decay,\n",
    "            num_test=10000,\n",
    "        )\n",
    "\n",
    "        for rnd_seed in range(1, 6):\n",
    "            # Set random seed for reproducibility\n",
    "            lightning.seed_everything(rnd_seed)\n",
    "\n",
    "            # Load the best checkpoint\n",
    "            ckpt_dir = project_root / Path(f\"output/{'ex-' * (not include_decay) + training_channel}/{training_mode}/{model.__class__.__name__}/{training_date}-rnd_seed{rnd_seed}/checkpoints\")\n",
    "            ckpt_path = get_best_ckpt(ckpt_dir, metric='valid_auc')\n",
    "            ckpt = torch.load(ckpt_dir / Path(ckpt_path))\n",
    "\n",
    "            # Remove 'model.' prefix from all keys in the state_dict\n",
    "            ckpt_state_dict = ckpt['state_dict']\n",
    "            ckpt_state_dict = {k.replace('model.', ''): v for k, v in ckpt_state_dict.items()}\n",
    "            model.load_state_dict(ckpt_state_dict, strict=False)\n",
    "            lit_model = BinaryLitModel(model=model)\n",
    "            lit_model.eval()\n",
    "            trainer = lightning.Trainer(logger=False)\n",
    "            result = trainer.test(lit_model, datamodule=lit_data_module)\n",
    "\n",
    "            df = pd.concat([df, pd.DataFrame({\n",
    "                'model': model.__class__.__name__,\n",
    "                'rnd_seed': rnd_seed,\n",
    "                'test_auc': result[0]['test_auc'],\n",
    "                'test_accuracy': result[0]['test_accuracy'],\n",
    "            }, index=[0])], ignore_index=True)\n",
    "\n",
    "    output_dir = project_root / Path('output/inference')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    df.to_csv(output_dir / f\"{'ex-' * (not include_decay) + training_channel}_to_{inference_channel}-{training_mode}-{training_date}{'-' * (information is not None) + information}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d517a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for training_mode in ['jet_flavor', 'jet_flavor_uni5', 'jet_flavor_uni10', 'jet_flavor_uni15']:\n",
    "    inference(\n",
    "        training_channel='diphoton',\n",
    "        training_mode=training_mode,\n",
    "        training_date='20250723_173318',\n",
    "        inference_channel='zz4l',\n",
    "        include_decay=True,\n",
    "        information='L=3000',\n",
    "    )\n",
    "    inference(\n",
    "        training_channel='diphoton',\n",
    "        training_mode=training_mode,\n",
    "        training_date='20250729_154839',\n",
    "        inference_channel='zz4l',\n",
    "        include_decay=True,\n",
    "        information='L=300',\n",
    "    )\n",
    "    inference(\n",
    "        training_channel='diphoton',\n",
    "        training_mode=training_mode,\n",
    "        training_date='20250721_121840',\n",
    "        inference_channel='zz4l',\n",
    "        include_decay=False,\n",
    "        information='L=3000',\n",
    "    )\n",
    "    inference(\n",
    "        training_channel='diphoton',\n",
    "        training_mode=training_mode,\n",
    "        training_date='20250731_015137',\n",
    "        inference_channel='zz4l',\n",
    "        include_decay=False,\n",
    "        information='L=300',\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cwola",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
