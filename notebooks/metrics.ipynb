{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03be0381",
   "metadata": {},
   "source": [
    "## Metrics (Training Results)\n",
    "\n",
    "This notebook shows the training results of different models, including CNN and Particle Transformer. Most of the training results are repeated 5 times with different random seeds.\n",
    "\n",
    "The signal and background were set to be Higgs from VBF and GGF, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ccbd0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "# Define the root of the project\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "def get_metrics(channel: str, data_mode: str, date_time: str, data_suffix: str = '', information: str = '', verbose: bool = True, num_rnd: int = None):\n",
    "    \"\"\"Print summary metrics for different models under given configuration.\"\"\"\n",
    "\n",
    "    # Print header\n",
    "    if verbose:\n",
    "        info_suffix = f\" ({information})\" if information else \"\"\n",
    "        print(f\"# Metrics for {channel}/{data_mode} at {date_time}{info_suffix}\")\n",
    "\n",
    "    # Define path to metrics output\n",
    "    output_dir = project_root / 'output' / channel / data_mode\n",
    "\n",
    "    # Loop through models\n",
    "    metrics = {}\n",
    "    for model in ['CNN_EventCNN', 'ParT_Light']:\n",
    "\n",
    "        # Collect metrics from each random seed run\n",
    "        tmp_metrics = []\n",
    "        rnd_seed = 0\n",
    "\n",
    "        while True:\n",
    "            metrics_file = output_dir / f\"{model}-{date_time}-{data_suffix}\" / f'rnd_seed-{rnd_seed}' / 'metrics.csv'\n",
    "            if not metrics_file.exists():\n",
    "                break\n",
    "\n",
    "            df_tmp = pd.read_csv(metrics_file)\n",
    "            tmp_metrics.append(df_tmp.tail(1))  # Use the last row (test result)\n",
    "            rnd_seed += 1\n",
    "\n",
    "            if num_rnd is not None and rnd_seed >= num_rnd:\n",
    "                break\n",
    "\n",
    "        # Print summary statistics if any runs were found\n",
    "        if tmp_metrics:\n",
    "            df = pd.concat(tmp_metrics, ignore_index=True)\n",
    "            acc_mean, acc_std = df['test_accuracy'].mean(), df['test_accuracy'].std()\n",
    "            auc_mean, auc_std = df['test_auc'].mean(), df['test_auc'].std()\n",
    "            epoch_mean, epoch_std = df['epoch'].mean(), df['epoch'].std()\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"{model:<15} ({len(tmp_metrics)} runs): \"\n",
    "                      f\"ACC {acc_mean:.3f} ± {acc_std:.3f} | \"\n",
    "                      f\"AUC {auc_mean:.3f} ± {auc_std:.3f} | \"\n",
    "                      f\"Epochs {epoch_mean:.1f} ± {epoch_std:.1f}\")\n",
    "            \n",
    "            metrics[model] = {'acc_mean': acc_mean, 'acc_std': acc_std, 'auc_mean': auc_mean, 'auc_std': auc_std}\n",
    "\n",
    "    if verbose:\n",
    "        print('\\n' + '-' * 80 + '\\n')\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53036cb",
   "metadata": {},
   "source": [
    "## $H \\rightarrow \\gamma \\gamma$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d46fdb7",
   "metadata": {},
   "source": [
    "### >>> Different luminosities monitored with `valid_auc`\n",
    "\n",
    "- `cop + pt_norm` preprocessings.\n",
    "- Test $L=100,300, 900,1800,3000~\\text{fb}^{-1}$.\n",
    "- Testing data is labeled by true class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c36432",
   "metadata": {},
   "outputs": [],
   "source": [
    "luminosities = [100, 300, 900, 1800, 3000]\n",
    "in_metrics = []\n",
    "ex_metrics = []\n",
    "\n",
    "for data_mode in ['jet_flavor']:\n",
    "    for L in luminosities:\n",
    "        in_metrics.append(get_metrics(channel='diphoton', data_mode=data_mode, date_time='20250819_010104', data_suffix=f'L{L}', verbose=False, num_rnd=10))\n",
    "        ex_metrics.append(get_metrics(channel='ex-diphoton', data_mode=data_mode, date_time='20250819_010104', data_suffix=f'L{L}', verbose=False, num_rnd=10))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "fig.suptitle(f\"Metrics under different luminosities\", fontsize=16)\n",
    "for model in ['CNN_EventCNN']:\n",
    "# for model in ['CNN_EventCNN', 'ParT_Light']:\n",
    "    ax[0].errorbar(luminosities, [m[model]['acc_mean'] for m in ex_metrics if m], yerr=[m[model]['acc_std'] for m in ex_metrics if m], marker='o', capsize=4, label=f\"w/o-photon {model}\")\n",
    "    ax[1].errorbar(luminosities, [m[model]['auc_mean'] for m in ex_metrics if m], yerr=[m[model]['auc_std'] for m in ex_metrics if m], marker='o', capsize=4, label=f\"w/o-photon {model}\")\n",
    "    ax[0].errorbar(luminosities, [m[model]['acc_mean'] for m in in_metrics if m], yerr=[m[model]['acc_std'] for m in in_metrics if m], marker='o', capsize=4, label=f\"w/-photon {model}\")\n",
    "    ax[1].errorbar(luminosities, [m[model]['auc_mean'] for m in in_metrics if m], yerr=[m[model]['auc_std'] for m in in_metrics if m], marker='o', capsize=4, label=f\"w/-photon {model}\")\n",
    "\n",
    "for i, ylabel in enumerate(['Accuracy', 'AUC']):\n",
    "    ax[i].set_xscale(\"log\")\n",
    "    ax[i].set(xlabel=\"Luminosity\", ylabel=ylabel)\n",
    "    ax[i].legend()\n",
    "    ax[i].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2181b29",
   "metadata": {},
   "source": [
    "### >>> Different luminosities monitored with `valid_loss`\n",
    "\n",
    "- `cop + pt_norm` preprocessings.\n",
    "- Test $L=100,300, 900,1800,3000~\\text{fb}^{-1}$.\n",
    "- Testing data is labeled by true class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "luminosities = [100, 300, 900, 1800, 3000]\n",
    "in_metrics = []\n",
    "ex_metrics = []\n",
    "\n",
    "for data_mode in ['jet_flavor']:\n",
    "    for L in luminosities:\n",
    "        in_metrics.append(get_metrics(channel='diphoton', data_mode=data_mode, date_time='20250819_010104', data_suffix=f'L{L}', verbose=False, num_rnd=10))\n",
    "        ex_metrics.append(get_metrics(channel='ex-diphoton', data_mode=data_mode, date_time='20250819_010104', data_suffix=f'L{L}', verbose=False, num_rnd=10))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "fig.suptitle(f\"Metrics under different luminosities\", fontsize=16)\n",
    "for model in ['CNN_EventCNN']:\n",
    "# for model in ['CNN_EventCNN', 'ParT_Light']:\n",
    "    ax[0].errorbar(luminosities, [m[model]['acc_mean'] for m in ex_metrics if m], yerr=[m[model]['acc_std'] for m in ex_metrics if m], marker='o', capsize=4, label=f\"w/o-photon {model}\")\n",
    "    ax[1].errorbar(luminosities, [m[model]['auc_mean'] for m in ex_metrics if m], yerr=[m[model]['auc_std'] for m in ex_metrics if m], marker='o', capsize=4, label=f\"w/o-photon {model}\")\n",
    "    ax[0].errorbar(luminosities, [m[model]['acc_mean'] for m in in_metrics if m], yerr=[m[model]['acc_std'] for m in in_metrics if m], marker='o', capsize=4, label=f\"w/-photon {model}\")\n",
    "    ax[1].errorbar(luminosities, [m[model]['auc_mean'] for m in in_metrics if m], yerr=[m[model]['auc_std'] for m in in_metrics if m], marker='o', capsize=4, label=f\"w/-photon {model}\")\n",
    "\n",
    "for i, ylabel in enumerate(['Accuracy', 'AUC']):\n",
    "    ax[i].set_xscale(\"log\")\n",
    "    ax[i].set(xlabel=\"Luminosity\", ylabel=ylabel)\n",
    "    ax[i].legend()\n",
    "    ax[i].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cwola",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
